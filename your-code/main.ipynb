{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LAB | GenAI: Exploring Prompting Techniques for Customer Support Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Learn and apply different prompting techniques to improve the performance of a language model in generating customer support responses.\n",
    "\n",
    "**Business Case:**\n",
    "\n",
    "Imagine you are working for a company that provides a variety of services, including technical support, billing inquiries, and general customer service. Your task is to use a language model to automate responses to customer emails.\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "Download the FAQ of a company to do this exercise. Below you have a couple of examples, but feel free to find your own:\n",
    " - https://info.undp.org/erecruit/documents/FAQ.pdf\n",
    " - https://www.cambridgeenglish.org/Images/696254-faqs-digital-cambridge-english-qualifications.pdf\n",
    " - https://www.wscc.nt.ca/sites/default/files/documents/0009-518-Item-04-INDESIGN-FAQ-Template%203%20-%20MINUS%20FIRST%20QUESTION.pdf\n",
    "\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Download and Read the PDF:\n",
    "\n",
    "  - Choose one of the provided FAQ PDFs or find your own relevant FAQ document.\n",
    "  - Read through the FAQ document carefully to understand the types of questions and answers it contains.\n",
    "  - Create Questions Based on the PDF ( you can use ChatGPT for this)\n",
    "    - Generate a list of potential customer questions that could be answered using the information from the FAQ PDF.\n",
    "    - Ensure your questions cover a variety of topics and difficulty levels found within the document.\n",
    "    - Generate Responses Using Different Prompting Techniques:\n",
    "\n",
    "Use a language model (such as ChatGPT) to generate responses to your questions.\n",
    "Experiment with different prompting techniques to see how they affect the quality of the responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of prompting\n",
    "\n",
    "For each of the types prompting, perform the following:\n",
    " - Research what the type of prompting is\n",
    " - Create a small explaination of the prompting\n",
    " - Test your type of prompting vs the control prompt (direct question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Zero-Shot Prompting\n",
    "\n",
    "Use the knowledge base to create prompts without examples.\n",
    "Test the model's ability to generate accurate responses based solely on the provided instructions.\n",
    "Assess the performance compared to few-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the available methods to contact customer support?\"\n",
    "zero_shot_prompt = f\"Answer the following customer inquiry: {question}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Few-Shot Prompting\n",
    "\n",
    "Select a few representative emails from each category.\n",
    "Create prompts by including these examples and ask the model to generate responses for new emails.\n",
    "Evaluate the quality and relevance of the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "Here are some examples of customer inquiries and responses:\n",
    "1. Inquiry: How do I cancel my subscription?\n",
    "   Response: You can cancel your subscription by going to the account settings and clicking on 'Cancel Subscription'.\n",
    "2. Inquiry: What is your refund policy?\n",
    "   Response: We offer a full refund within 30 days of purchase if you are not satisfied with our services.\n",
    "   \n",
    "Now, answer the following inquiry:\n",
    "Inquiry: How can I upgrade my account?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain of Thought Prompting\n",
    "\n",
    "Develop prompts that guide the model to think through the problem step-by-step before providing the final answer.\n",
    "Analyze if this approach improves the quality of technical support responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_of_thought_prompt = \"Explain how a customer can troubleshoot login issues step by step.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruction-Based Prompting\n",
    "\n",
    "Write clear and explicit instructions in the prompts for each type of customer inquiry.\n",
    "Measure the effectiveness of detailed instructions in guiding the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_based_prompt = \"Please provide a detailed response to the following customer inquiry: How do I reset my password?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role-Playing Prompting\n",
    "\n",
    "Ask the model to respond as a customer service representative or technical support expert.\n",
    "Evaluate how well the model adopts the role and provides relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_playing_prompt = \"You are a customer service representative. A customer asks: What are your operating hours? Respond as if you are assisting them.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Prompting\n",
    "\n",
    "Provide relevant context from previous email threads or the knowledge base before posing the main question.\n",
    "Test if providing context improves the accuracy and relevance of the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_context = \"Customer: I have an issue with my account.\"\n",
    "main_question = \"What steps should I take to resolve this?\"\n",
    "contextual_prompt = f\"{previous_context}\\nNow answer: {main_question}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Prompting\n",
    "\n",
    "Create a dialogue-style prompt where the model continues an ongoing conversation with the customer.\n",
    "Observe how well the model maintains context and coherence in multi-turn conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_prompt = \"Customer: I need help with my recent order.\\nAssistant:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Prompting\n",
    "\n",
    "Show the model examples of both good and bad responses.\n",
    "Use these contrasting examples to guide the model towards generating better responses.\n",
    "Compare the results with other techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_prompt = \"\"\"\n",
    "Bad Response: \"I don't know.\"\n",
    "Good Response: \"Please provide your order number, and I can assist you with your inquiry.\"\n",
    "\n",
    "Now, answer the following inquiry:\n",
    "Inquiry: Can you tell me how to track my order?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity Prompting\n",
    "\n",
    "Ask the model to respond with a specific style, tone, or level of detail, such as formal, friendly, or concise.\n",
    "Assess how well the model adapts its responses to the specified requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity_prompt = \"Respond to the customer in a friendly and concise manner: How can I update my email address?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Refinement Prompting\n",
    "\n",
    "Ask the model to refine or improve upon its previous response.\n",
    "Experiment with multiple iterations to see if responses improve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_response = \"You can contact us through our website.\"\n",
    "refinement_prompt = f\"Refine this response: {initial_response}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
