{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LAB | GenAI: Exploring Prompting Techniques for Customer Support Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Learn and apply different prompting techniques to improve the performance of a language model in generating customer support responses.\n",
    "\n",
    "**Business Case:**\n",
    "\n",
    "Imagine you are working for a company that provides a variety of services, including technical support, billing inquiries, and general customer service. Your task is to use a language model to automate responses to customer emails.\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "Download the FAQ of a company to do this exercise. Below you have a couple of examples, but feel free to find your own:\n",
    " - https://info.undp.org/erecruit/documents/FAQ.pdf\n",
    " - https://www.cambridgeenglish.org/Images/696254-faqs-digital-cambridge-english-qualifications.pdf\n",
    " - https://www.wscc.nt.ca/sites/default/files/documents/0009-518-Item-04-INDESIGN-FAQ-Template%203%20-%20MINUS%20FIRST%20QUESTION.pdf\n",
    "\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Download and Read the PDF:\n",
    "\n",
    "  - Choose one of the provided FAQ PDFs or find your own relevant FAQ document.\n",
    "  - Read through the FAQ document carefully to understand the types of questions and answers it contains.\n",
    "  - Create Questions Based on the PDF ( you can use ChatGPT for this)\n",
    "    - Generate a list of potential customer questions that could be answered using the information from the FAQ PDF.\n",
    "    - Ensure your questions cover a variety of topics and difficulty levels found within the document.\n",
    "    - Generate Responses Using Different Prompting Techniques:\n",
    "\n",
    "Use a language model (such as ChatGPT) to generate responses to your questions.\n",
    "Experiment with different prompting techniques to see how they affect the quality of the responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of prompting\n",
    "\n",
    "For each of the types prompting, perform the following:\n",
    " - Research what the type of prompting is\n",
    " - Create a small explaination of the prompting\n",
    " - Test your type of prompting vs the control prompt (direct question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Zero-Shot Prompting\n",
    "\n",
    "Use the knowledge base to create prompts without examples.\n",
    "Test the model's ability to generate accurate responses based solely on the provided instructions.\n",
    "Assess the performance compared to few-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = 'Can I bring a pen and paper to the exam to take notes?'\n",
    "\n",
    "prompt = f\"\"\"\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Few-Shot Prompting\n",
    "\n",
    "Select a few representative emails from each category.\n",
    "Create prompts by including these examples and ask the model to generate responses for new emails.\n",
    "Evaluate the quality and relevance of the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = \"\"\"Q: Can I bring a pen and paper to the exam to take notes?\n",
    "                A: You can bring a pen or pencil to take notes. The paper will be provided by the exam centre. Leave the paper on the table once the exam is finished.\n",
    "\n",
    "                Q: If I can’t answer a question, can I come back to it again later?\n",
    "                A: Yes, you can check and change your answers at any time before the end of the test.\n",
    "\n",
    "                Q: How will I know which questions I haven’t answered yet?\n",
    "                \"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain of Thought Prompting\n",
    "\n",
    "Develop prompts that guide the model to think through the problem step-by-step before providing the final answer.\n",
    "Analyze if this approach improves the quality of technical support responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = \"\"\"Q: An object with a mass of 10 kg is travelling at 10 m/s. Calculate its kynetic energy.\n",
    "                A: Kynetic energy is defined as the mass of an object times its velocity squared divided by 2. So the kynetic energy of the object is 10 kg times (10 m/s)^2 divided by 2, which equals 500 Joules.\n",
    "\n",
    "                Q: A 5 lbs object starts falling from a 60 meter high platform. Calculate its potential energy at t=0\n",
    "                \"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruction-Based Prompting\n",
    "\n",
    "Write clear and explicit instructions in the prompts for each type of customer inquiry.\n",
    "Measure the effectiveness of detailed instructions in guiding the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = \"\"\"Q: How can I make notes?\n",
    "                A: Step 1: Select the passage you would like to make notes about\n",
    "                   Step 2: Right click and choose “Note”\n",
    "                   Step 3: Copy and paste from your electronic notes to the answers\n",
    "\n",
    "                Q: Can I see all the text and questions at the same time?\n",
    "                \"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role-Playing Prompting\n",
    "\n",
    "Ask the model to respond as a customer service representative or technical support expert.\n",
    "Evaluate how well the model adopts the role and provides relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = \"\"\"How can I underline or highlight text?\n",
    "                \"\"\"\n",
    "\n",
    "prompt = f\"\"\"# Role: You're a technical support expert. Provide relevant information to the customer's questions\n",
    "        User request: {user_input}\n",
    "        \"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Prompting\n",
    "\n",
    "Provide relevant context from previous email threads or the knowledge base before posing the main question.\n",
    "Test if providing context improves the accuracy and relevance of the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = \"\"\"How can I underline or highlight text?\n",
    "                \"\"\"\n",
    "\n",
    "prompt = f\"\"\"# Context: The users will ask you questions regarding the contents of this url: https://www.cambridgeenglish.org/\n",
    "            User request: {user_input}\n",
    "        \"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Prompting\n",
    "\n",
    "Create a dialogue-style prompt where the model continues an ongoing conversation with the customer.\n",
    "Observe how well the model maintains context and coherence in multi-turn conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = \"\"\"I want to learn how to cook\n",
    "                \"\"\"\n",
    "\n",
    "prompt = f\"\"\" # Example:\n",
    "                User: Hi! I'm interested in learning Python but don't know where to start. Any suggestions?\n",
    "                Assistant: Absolutely! Python is a great choice for beginners because it’s easy to read and versatile. Could you tell me a bit about your goals with Python?\n",
    "                User: I think data analysis would be most helpful for my job.\n",
    "                Assistant: Great! For data analysis, I'd recommend starting with the basics of Python syntax, then exploring libraries like Pandas. How much time per week can you dedicate to learning?\n",
    "                User: I can spare about 5 hours each week.\n",
    "                Assistant: Perfect! In that case, start with a structured online course or a beginner book.\n",
    "\n",
    "                User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Prompting\n",
    "\n",
    "Show the model examples of both good and bad responses.\n",
    "Use these contrasting examples to guide the model towards generating better responses.\n",
    "Compare the results with other techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = \"\"\"Q: If I can’t answer a question, can I come back to it again later?\n",
    "                Right Answer: Yes, you can check and change your answers at any time before the end of the test.\n",
    "                Wrong Answer: No\n",
    "\n",
    "                Q: Can I see all the text and questions at the same time?\n",
    "                \"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity Prompting\n",
    "\n",
    "Ask the model to respond with a specific style, tone, or level of detail, such as formal, friendly, or concise.\n",
    "Assess how well the model adapts its responses to the specified requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = \"\"\"Q: Can I see all the text and questions at the same time?\n",
    "                \"\"\"\n",
    "\n",
    "prompt = f\"\"\" #Target: Your target audience is a high school or college student. Be concise, clear and use simple vocabulary and structures. Be friendly and not too formal.\n",
    "\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Refinement Prompting\n",
    "\n",
    "Ask the model to refine or improve upon its previous response.\n",
    "Experiment with multiple iterations to see if responses improve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load and set our key\n",
    "openai_api_key = input(\"Enter your API-key\")\n",
    "\n",
    "model_gpt = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "user_input = \"\"\"Write a job description for a Data Scientist.\n",
    "\n",
    "                Write a job description for a Data Scientist, emphasizing skills in data visualization, Python programming, and machine learning.\n",
    "\n",
    "                Expand the job description for a Data Scientist to include problem-solving and communication skills as essential qualities.\n",
    "\n",
    "                Ensure the job description highlights collaboration with cross-functional teams and emphasizes effective communication for both technical and non-technical audiences.\n",
    "                \"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "User request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "messages=[ # messages parameter must be a list of dictionaries\n",
    "    # can be as short as one message or many back and forth turns.\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "  ]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = messages,\n",
    "    model = model_gpt,\n",
    "    temperature=1,\n",
    "    max_tokens=60,\n",
    ")\n",
    "\n",
    "answer = chat_completion.choices[0].message.content\n",
    "# Display the Markdown\n",
    "display(Markdown(answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
